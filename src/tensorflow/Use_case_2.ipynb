{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sq77vpS_vuWI"
   },
   "source": [
    "# Use case 2 - IMSP 1st DATA Science school\n",
    "\n",
    "We recall the use case here: \n",
    "\n",
    "You are a software developper and you want to build an application for botanists to help them recognize\n",
    "different specices of medecinal flowers. Users on field take pictures of the flowers and the model return the\n",
    "type of corresponding category with a certain confidence. The predicted category can then be used to know\n",
    "the medecinal vertues of the plant. Predictions will be based on data collected from different practitioners.\n",
    "\n",
    "Dataset is dowloaded from Kaggle. Find the dataset actual description here\n",
    "https://www.kaggle.com/alxmamaev/flowers-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab_Manipulations.pdf        OtherCommands\r\n",
      "conda-cheatsheet.pdf\t       serving\r\n",
      "Delai_rdv_pediatres_2012.xlsx  TF_dev_initiation.ipynb\r\n",
      "deseases_client.ipynb\t       TF_dev_initiation.ipynb - Colaboratory.pdf\r\n",
      "environment.yml\t\t       Untitled.ipynb\r\n",
      "flowers_client.ipynb\t       Use_Case_1.ipynb\r\n",
      "insurance.csv\t\t       Use_case_2.ipynb\r\n",
      "my_model\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bt1pogo5Gdf8"
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "import pandas\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8WUCP4_3Gfer",
    "outputId": "bb914122-4d08-448c-cfa0-eabc28e0370a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n"
     ]
    }
   ],
   "source": [
    "# Set the path of the input folder \n",
    "\n",
    "data = \"/media/habib/Data/IMSP/ROetOptimisation/DATASETS/flowers/flowers/\"\n",
    "\n",
    "# List out the directories inside the main input folder\n",
    "folders = os.listdir(data)\n",
    "LABELS = folders\n",
    "print(LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "pt_icCEx6fOZ"
   },
   "source": [
    "## Looking at Friendly libraries not TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "YznEzh-vG1zS"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Import the images and resize them to a 128*128 size\n",
    "# Also generate the corresponding labels\n",
    "\n",
    "image_names = []\n",
    "train_labels = []\n",
    "train_images = []\n",
    "\n",
    "size = 64,64\n",
    "\n",
    "for folder in folders:\n",
    "    for file in os.listdir(os.path.join(data,folder)):\n",
    "        if file.endswith(\"jpg\"):\n",
    "            image_names.append(os.path.join(data,folder,file))\n",
    "            train_labels.append(folder)\n",
    "            #cv2 openCV package\n",
    "            img = cv2.imread(os.path.join(data,folder,file))\n",
    "            im = cv2.resize(img,size)\n",
    "            train_images.append(im)\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "# Extract the labels\n",
    "label_dummies = pandas.get_dummies(train_labels)\n",
    "labels =  label_dummies.values.argmax(1)\n",
    "\n",
    "# Transform the image array to a numpy type\n",
    "train = np.array(train_images)\n",
    "train.shape\n",
    "\n",
    "# Reduce the RGB values between 0 and 1\n",
    "train = train.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "TIqXzI6YHJBo"
   },
   "outputs": [],
   "source": [
    "pandas.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "RJXZW7XWHOzR"
   },
   "outputs": [],
   "source": [
    "pandas.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "EyxHGExcHTJI"
   },
   "outputs": [],
   "source": [
    "# Shuffle the labels and images randomly for better results\n",
    "\n",
    "union_list = list(zip(train, labels))\n",
    "random.shuffle(union_list)\n",
    "train,labels = zip(*union_list)\n",
    "\n",
    "# Convert the shuffled list to numpy array type\n",
    "\n",
    "train = np.array(train)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VMu5zr705SP3"
   },
   "source": [
    "## Doing the same thing with TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "BfTvJkLz5Vdg",
    "outputId": "8f77673b-8e81-4bbb-d92d-fe8a9fa9f2ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching  daisy  images\n",
      "Fetching  dandelion  images\n",
      "Fetching  rose  images\n",
      "Fetching  sunflower  images\n",
      "Fetching  tulip  images\n"
     ]
    }
   ],
   "source": [
    "#Image size\n",
    "image_dim_tensor = 64\n",
    "\n",
    "#Reads an image from a file, decodes it into a dense tensor, and resizes it\n",
    "# to a fixed shape.\n",
    "def _parse_function(filename, label):\n",
    "  size = image_dim_tensor,image_dim_tensor\n",
    "  NUM_CLASSES = len(LABELS)\n",
    "  \n",
    "  image_string = tf.read_file(filename)\n",
    "  image_decoded = tf.image.decode_jpeg(image_string)\n",
    "  image_resized = tf.image.resize_images(image_decoded, size)\n",
    "  image_resized = tf.cast(image_resized , tf.float32) * (1. / 255.0)\n",
    "  #If a one_hot representation of the labels should be used\n",
    "  one_hot_label = tf.one_hot(label, NUM_CLASSES)\n",
    "  \n",
    "  return {\"new_image\": image_resized}, label\n",
    "\n",
    "def _parse_pred_function(filename):\n",
    "  size = image_dim_tensor,image_dim_tensor\n",
    "  \n",
    "  image_string = tf.read_file(filename)\n",
    "  image_decoded = tf.image.decode_jpeg(image_string)\n",
    "  image_resized = tf.image.resize_images(image_decoded, size)\n",
    "  \n",
    "  image_resized = tf.cast(image_resized , tf.float32) * (1. / 255.0)\n",
    "  \n",
    "  return {\"new_image\": image_resized}\n",
    "\n",
    "\n",
    "filenames = []\n",
    "labels_names = []\n",
    "\n",
    "#For running efficiency we will keep only 200 images at mostper label\n",
    "max_num_imgs = 200\n",
    "\n",
    "p = tf.constant(0.2)\n",
    "\n",
    "for folder in folders:\n",
    "  print(\"Fetching \",folder, \" images\")\n",
    "  fecthed_imgs = 0\n",
    "  for file in os.listdir(os.path.join(data,folder)):\n",
    "    if file.endswith(\"jpg\"):\n",
    "      if fecthed_imgs > max_num_imgs:\n",
    "        break\n",
    "      else:\n",
    "        filenames.append(os.path.join(data,folder,file))\n",
    "        labels_names.append(folder)        \n",
    "    else:\n",
    "      continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mdTHEYDUSHIs"
   },
   "outputs": [],
   "source": [
    "# Shuffle the input set because of ordered sequential loading.\n",
    "order = np.argsort(np.random.random(len(labels_names)))\n",
    "filenames = [filenames[i] for i in order]\n",
    "labels_names = [labels_names[i] for i in order]\n",
    "\n",
    "# `labels[i]` is the label for the image in `filenames[i].\n",
    "# Extract the labels as integer\n",
    "label_dummies = pandas.get_dummies(labels_names)\n",
    "labels =  label_dummies.values.argmax(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wZ5poM4tTemL"
   },
   "outputs": [],
   "source": [
    "DATASET_SIZE = len(filenames)\n",
    "#int(DATASET_SIZE*0.8)\n",
    "\n",
    "train_size = int(0.8 * DATASET_SIZE)\n",
    "test_size = int(0.2 * DATASET_SIZE)\n",
    "\n",
    "train_filenames = filenames[:train_size]\n",
    "train_labels_names = labels[:train_size]\n",
    "\n",
    "test_filenames = filenames[train_size:]\n",
    "test_labels_names = labels[train_size:]\n",
    "\n",
    "#Take 10 images from the test set for prediction\n",
    "some_images = test_filenames[0:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "WyzIyQMXmCLd"
   },
   "source": [
    "## Deprecated way to input an Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "ckrdEfc4Nkpl"
   },
   "outputs": [],
   "source": [
    "class FlowersData(object):    \n",
    "     \n",
    "    def __init__(self, tf_dataset, reshape):\n",
    "        self.pos = 0\n",
    "        self.images = None\n",
    "        self.labels = None\n",
    "        # load entire Dataset into memory by chunks of 10000\n",
    "        tf_dataset = tf_dataset.batch(10000)\n",
    "        tf_dataset = tf_dataset.repeat(1)\n",
    "        features, labels = tf_dataset.make_one_shot_iterator().get_next()         \n",
    "        with tf.Session() as sess:\n",
    "            while True:\n",
    "                try:\n",
    "                    feats, labs = sess.run([features, labels])\n",
    "                    #print(labs)\n",
    "                    self.images = feats if self.images is None else np.concatenate([self.images, feats])\n",
    "                    self.labels = labs if self.labels is None else np.concatenate([self.labels, labs])\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(filenames, labels)\n",
    "dataset = dataset.map(_parse_function)\n",
    "\n",
    "dataset = dataset.shuffle(10000)\n",
    "\n",
    "train_dataset = dataset.take(train_size)\n",
    "test_dataset =  dataset.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "NDlzM02om0Vm"
   },
   "outputs": [],
   "source": [
    "test = FlowersData(test_dataset, False)\n",
    "train = FlowersData(train_dataset, False)\n",
    "print('Done loading images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "yJOjiGRZm7YZ"
   },
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(    \n",
    "    x={\"new_image\": np.array(train.images[\"image_data\"])},\n",
    "    y=np.array(train.labels),\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\t\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(    \n",
    "    x={\"new_image\": np.array(test.images[\"image_data\"])},\n",
    "    y=np.array(test.labels),\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "\t\n",
    "#Take 10 images from the test set for prediction\n",
    "some_images = np.array(test.images[\"image_data\"])\n",
    "some_images =some_images[0:9]\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"new_image\": some_images},\n",
    "    num_epochs=1,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "hidden": true,
    "id": "IKxqqZ2bPO-c",
    "outputId": "fedaf7ee-e11c-437f-db65-c058c73ae706"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3458,)"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Length of the training set\n",
    "np.array(train.labels).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z4yJi7hzmebM"
   },
   "source": [
    "## Recommanded way to input an Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K3CexJ-xADph"
   },
   "outputs": [],
   "source": [
    "def train_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # A vector of filenames.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "    dataset = dataset.map(_parse_function)\n",
    "\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.shuffle(10000).repeat().batch(batch_size)\n",
    "\n",
    "    # Return the dataset.\n",
    "    return dataset\n",
    "  \n",
    "  \n",
    "def test_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "    dataset = dataset.map(_parse_function)\n",
    "    \n",
    "    #batch the examples\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    # Return the dataset.\n",
    "    return dataset  \n",
    "  \n",
    "def predict_input_fn(features):\n",
    "  batch_size = 10\n",
    "  dataset = tf.data.Dataset.from_tensor_slices(features)\n",
    "  dataset = dataset.map(_parse_pred_function)\n",
    "  \n",
    "  dataset = dataset.batch(batch_size)\n",
    "  return dataset.make_one_shot_iterator().get_next()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JCB0jJVpn8CG"
   },
   "source": [
    "## Building the model\n",
    "\n",
    "The model used is a CNN with 3 layers including 2 convolution layers and one Dense layer at the head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-POMxeEsOsIV"
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    x = features[\"new_image\"]\n",
    "\n",
    "    # The convolutional layers expect 4-rank tensors\n",
    "    # but x is a 2-rank tensor, so reshape it.\n",
    "    net = tf.reshape(x, [-1, 64, 64, 3])    \n",
    "    # First convolutional layer.\n",
    "    net = tf.layers.conv2d(inputs=net, name='layer_conv1',\n",
    "                           filters=16, kernel_size=5,\n",
    "                           padding='same', activation=tf.nn.relu)\n",
    "    net = tf.layers.max_pooling2d(inputs=net, pool_size=2, strides=2)\n",
    "    # Second convolutional layer.\n",
    "    net = tf.layers.conv2d(inputs=net, name='layer_conv2',\n",
    "                           filters=36, kernel_size=5,\n",
    "                           padding='same', activation=tf.nn.relu)\n",
    "    net = tf.layers.max_pooling2d(inputs=net, pool_size=2, strides=2)    \n",
    "    # Flatten to a 2-rank tensor.\n",
    "    net = tf.contrib.layers.flatten(net)\n",
    "    # First fully-connected / dense layer.\n",
    "    # This uses the ReLU activation function.\n",
    "    net = tf.layers.dense(inputs=net, name='layer_fc1',\n",
    "                          units=128, activation=tf.nn.relu)    \n",
    "    # Second fully-connected / dense layer.\n",
    "    # This is the last layer so it does not use an activation function.\n",
    "    net = tf.layers.dense(inputs=net, name='layer_fc2',\n",
    "                          units=len(LABELS))\n",
    "    # Logits output of the neural network.\n",
    "    logits = net\n",
    "    \n",
    "    label_values = tf.constant(LABELS)\n",
    "    \n",
    "    # Softmax output of the neural network.\n",
    "    y_pred = tf.nn.softmax(logits=logits)\n",
    "    \n",
    "    # Classification output of the neural network.\n",
    "    y_pred_cls = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:      \n",
    "      # Convert predicted_indices back into strings.\n",
    "      predictions = {\n",
    "          'classes': tf.gather(label_values, y_pred_cls),\n",
    "          'scores': tf.reduce_max(y_pred, axis=1)\n",
    "      }\n",
    "      export_outputs = {\n",
    "          'prediction': tf.estimator.export.PredictOutput(predictions)\n",
    "      }\n",
    "      \n",
    "      # If the estimator is supposed to be in prediction-mode \n",
    "      spec = tf.estimator.EstimatorSpec(mode, predictions=predictions, export_outputs=export_outputs)               \n",
    "    else:\n",
    "        # Otherwise the estimator is supposed to be in either\n",
    "        # training or evaluation-mode. Note that the loss-function\n",
    "        # is also required in Evaluation mode.\n",
    "        \n",
    "        # Define the loss-function to be optimized, by first\n",
    "        # calculating the cross-entropy between the output of\n",
    "        # the neural network and the true labels for the input data.\n",
    "        # This gives the cross-entropy for each image in the batch.\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels,\n",
    "                                                                       logits=logits)\n",
    "\n",
    "        # Reduce the cross-entropy batch-tensor to a single number\n",
    "        # which can be used in optimization of the neural network.\n",
    "        loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "        # Define the optimizer for improving the neural network.\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=params[\"learning_rate\"])\n",
    "\n",
    "        # Get the TensorFlow op for doing a single optimization step.\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss, global_step=tf.train.get_global_step())\n",
    "\n",
    "        # Define the evaluation metrics,\n",
    "        # in this case the classification accuracy.\n",
    "        metrics = \\\n",
    "        {\n",
    "            \"accuracy\": tf.metrics.accuracy(labels, y_pred_cls)\n",
    "        }\n",
    "\n",
    "        # Wrap all of this in an EstimatorSpec.\n",
    "        spec = tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=loss,\n",
    "            train_op=train_op,\n",
    "            eval_metric_ops=metrics)\n",
    "        \n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "id": "ck8LQSPygXKm",
    "outputId": "a09b4fb5-08e2-4006-bf94-88d633faa1a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './my_model/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f165feb6f60>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "#Specify hyper-parameters \n",
    "params = {\"learning_rate\": 1e-4}\n",
    "\n",
    "model = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                               params=params,\n",
    "                               model_dir=\"./my_model/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_MIWoZYUoiBU"
   },
   "source": [
    "## Training the model\n",
    "This will take some time depending on the runing environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "-rj-JKcAgfJv",
    "outputId": "5d46d93b-0c2c-429f-eb9d-87ce03491e3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./my_model/model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 200 into ./my_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.90758187, step = 201\n",
      "INFO:tensorflow:Saving checkpoints for 211 into ./my_model/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 232 into ./my_model/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 252 into ./my_model/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 290 into ./my_model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.038319\n",
      "INFO:tensorflow:loss = 0.7697071, step = 301 (2609.490 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 346 into ./my_model/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 387 into ./my_model/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 400 into ./my_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.6649903.\n",
      "****************** FINISHED TRAINING **********************\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-13-06:43:46\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./my_model/model.ckpt-400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-13-06:44:10\n",
      "INFO:tensorflow:Saving dict for global step 400: accuracy = 0.65086704, global_step = 400, loss = 0.8409868\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 400: ./my_model/model.ckpt-400\n",
      "Classification accuracy: 65.09%\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "#model.train(input_fn=train_input_fn, steps=500)\n",
    "model.train(input_fn= lambda : train_input_fn(train_filenames, train_labels_names, 1000), steps=200)\n",
    "\n",
    "print(\"****************** FINISHED TRAINING **********************\")\n",
    "\n",
    "#result = model.evaluate(input_fn=test_input_fn)\n",
    "result = model.evaluate(input_fn= lambda : test_input_fn(test_filenames, test_labels_names, 1000))\n",
    "\n",
    "#Acuraccy\n",
    "print(\"Classification accuracy: {0:.2%}\".format(result[\"accuracy\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TwYA_qh8pECf"
   },
   "source": [
    "## Runing the predictions\n",
    "We evaluate the model on a bunch of images. 10 images were selected from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "RrRvH8lyXbvy",
    "outputId": "ed8a9553-cc36-4ad1-cc07-b24a254d3eb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./my_model/model.ckpt-400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "{'classes': b'dandelion', 'scores': 0.86428434}\n",
      "{'classes': b'daisy', 'scores': 0.51471925}\n",
      "{'classes': b'daisy', 'scores': 0.62386924}\n",
      "{'classes': b'tulip', 'scores': 0.79162294}\n",
      "{'classes': b'tulip', 'scores': 0.6998274}\n",
      "{'classes': b'rose', 'scores': 0.48443404}\n",
      "{'classes': b'dandelion', 'scores': 0.8203398}\n",
      "{'classes': b'rose', 'scores': 0.75211614}\n",
      "{'classes': b'daisy', 'scores': 0.44793501}\n"
     ]
    }
   ],
   "source": [
    "#Predictions\t\n",
    "predictions = model.predict(input_fn=lambda : predict_input_fn(some_images))\n",
    "for pred in predictions:\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/habib/Data/IMSP/ROetOptimisation/DATASETS/flowers/flowers/daisy/14264136211_9531fbc144.jpg',\n",
       " '/media/habib/Data/IMSP/ROetOptimisation/DATASETS/flowers/flowers/daisy/5058708968_8bdcd29e63_n.jpg',\n",
       " '/media/habib/Data/IMSP/ROetOptimisation/DATASETS/flowers/flowers/tulip/19689681344_b05ac361f2_n.jpg',\n",
       " '/media/habib/Data/IMSP/ROetOptimisation/DATASETS/flowers/flowers/sunflower/4235259239_21f2eb4f2e.jpg',\n",
       " '/media/habib/Data/IMSP/ROetOptimisation/DATASETS/flowers/flowers/sunflower/2996573407_5e473b9359.jpg',\n",
       " '/media/habib/Data/IMSP/ROetOptimisation/DATASETS/flowers/flowers/sunflower/14858674096_ed0fc1a130.jpg',\n",
       " '/media/habib/Data/IMSP/ROetOptimisation/DATASETS/flowers/flowers/dandelion/2469856983_fe8e36ba57.jpg',\n",
       " '/media/habib/Data/IMSP/ROetOptimisation/DATASETS/flowers/flowers/daisy/2908212142_5437fa67ff_n.jpg',\n",
       " '/media/habib/Data/IMSP/ROetOptimisation/DATASETS/flowers/flowers/tulip/8619064872_dea79a9eb9.jpg']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uREVjagXYxWJ",
    "outputId": "f4c82f85-f207-4b1f-927e-06eac761211c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'dandelion' b'tulip' b'tulip' b'tulip' b'tulip' b'tulip' b'dandelion'\n",
      " b'rose' b'sunflower']\n"
     ]
    }
   ],
   "source": [
    "some_labels = test_labels_names\n",
    "with tf.Session() as sess:\n",
    "  preds = sess.run(tf.gather(LABELS, some_labels[0:9]))\n",
    "  print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "q3jfgswLQeFS",
    "outputId": "37d78ece-cbce-4200-dd41-0069e17d4186"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "CNVj5v49tkNS",
    "outputId": "7c87a733-1006-43b9-83c9-025bcdad6dad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab_Manipulations.pdf        my_model\r\n",
      "conda-cheatsheet.pdf\t       OtherCommands\r\n",
      "Delai_rdv_pediatres_2012.xlsx  TF_dev_initiation.ipynb\r\n",
      "deseases_client.ipynb\t       TF_dev_initiation.ipynb - Colaboratory.pdf\r\n",
      "environment.yml\t\t       Untitled.ipynb\r\n",
      "flowers_client.ipynb\t       Use_Case_1.ipynb\r\n",
      "insurance.csv\t\t       Use_case_2.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ds701LZvKRy"
   },
   "source": [
    "## Export the model for Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "HjS1NRiAvIc1",
    "outputId": "525a23ab-853c-4f21-dcc7-0fe406c357cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['prediction', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from ./my_model/model.ckpt-400\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: serving/versions/temp-b'1544684366'/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'serving/versions/1544684366'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Description of input features to the model\n",
    "feature_spec = {'new_image': tf.FixedLenFeature(shape=[], dtype=tf.float32), }\n",
    "\n",
    "#Exporting the model\n",
    "export_path_base = 'serving/versions'\n",
    "\n",
    "model.export_savedmodel(export_path_base, tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\r\n",
      "\r\n",
      "signature_def['prediction']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "    inputs['examples'] tensor_info:\r\n",
      "        dtype: DT_STRING\r\n",
      "        shape: (-1)\r\n",
      "        name: input_example_tensor:0\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['classes'] tensor_info:\r\n",
      "        dtype: DT_STRING\r\n",
      "        shape: (-1)\r\n",
      "        name: GatherV2:0\r\n",
      "    outputs['scores'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1)\r\n",
      "        name: Max:0\r\n",
      "  Method name is: tensorflow/serving/predict\r\n",
      "\r\n",
      "signature_def['serving_default']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "    inputs['examples'] tensor_info:\r\n",
      "        dtype: DT_STRING\r\n",
      "        shape: (-1)\r\n",
      "        name: input_example_tensor:0\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['classes'] tensor_info:\r\n",
      "        dtype: DT_STRING\r\n",
      "        shape: (-1)\r\n",
      "        name: GatherV2:0\r\n",
      "    outputs['scores'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1)\r\n",
      "        name: Max:0\r\n",
      "  Method name is: tensorflow/serving/predict\r\n"
     ]
    }
   ],
   "source": [
    "#Examine your saved model\n",
    "!saved_model_cli show --dir \"serving/versions/1544677631\" --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tee: /etc/apt/sources.list.d/tensorflow-serving.list: Permission non accordée\n",
      "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
      "Lecture des listes de paquets... Fait\n",
      "W: chmod 0700 of directory /var/lib/apt/lists/partial failed - SetupAPTPartialDirectory (1: Opération non permise)\n",
      "E: Impossible d'ouvrir le fichier verrou /var/lib/apt/lists/lock - open (13: Permission non accordée)\n",
      "E: Impossible de verrouiller le répertoire /var/lib/apt/lists/\n",
      "W: Problème de suppression du lien /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission non accordée)\n",
      "W: Problème de suppression du lien /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission non accordée)\n"
     ]
    }
   ],
   "source": [
    "# Add TensorFlow Serving distribution URI as a package source\n",
    "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
    "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
    "!apt update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Impossible d'ouvrir le fichier verrou /var/lib/dpkg/lock - open (13: Permission non accordée)\r\n",
      "E: Impossible de verrouiller le répertoire d'administration (/var/lib/dpkg/). Avez-vous les privilèges du superutilisateur ?\r\n"
     ]
    }
   ],
   "source": [
    "# Install TensorFlow Serving\n",
    "!apt-get install tensorflow-model-server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorflow_model_server --port=9000 --model_name=Flowers --model_base_path='/home/habib/Documents/serving/versions/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://www.tensorflow.org/serving/tutorials/Serving_REST_simple\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "pt_icCEx6fOZ"
   ],
   "name": "Use_case_2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:my_env]",
   "language": "python",
   "name": "conda-env-my_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
